\documentclass{article}
\usepackage{amsmath}

\begin{document}

\section*{Research}

\subsection{Real Time Facial Emotion Recognition Using Deep Learning Models}
\begin{enumerate}
    \item \textbf{Convolutional Neural Networks (CNNs)}:
    \begin{itemize}
        \item CNNs are emphasized as the most effective model for facial emotion recognition due to their ability to capture spatial features from images.
        \item CNNs employ convolutional layers with learnable filters to detect patterns like edges and textures.
        \item Techniques such as max-pooling reduce spatial dimensions while retaining significant features.
        \item Fully connected layers map extracted features to emotion classes, leveraging softmax for multi-class classification.
        \item Batch normalization and dropout are incorporated to enhance stability and reduce overfitting.
    \end{itemize}
    \item \textbf{Residual Neural Network (ResNet-50)}:
    \begin{itemize}
        \item ResNet-50, known for its depth (50 layers) and use of residual connections, addresses the vanishing gradient problem.
        \item Its deeper architecture allows it to capture complex features, though at the cost of higher computational requirements.
        \item This model showed lower suitability for real-time tasks due to its resource intensiveness.
    \end{itemize}
    \item \textbf{Recurrent Neural Networks (RNNs)}:
    \begin{itemize}
        \item RNNs handle temporal dependencies in data, suitable for video-based emotion detection.
        \item They process sequences with recurrent connections and internal memory to retain context over time.
        \item Models like LSTM and BLSTM are highlighted for their ability to integrate temporal features for improved emotion recognition.
    \end{itemize}
    \item \textbf{Dual-Temporal Scale CNN (DTSCNN)}:
    \begin{itemize}
        \item This newer architecture uses two convolutional layers with different kernel sizes to capture both local and global patterns in temporal data.
        \item Particularly useful for applications like audio and video emotion recognition.
        \item DTSCNN models achieved good accuracy but require more research to mature.
    \end{itemize}
\end{enumerate}

\section*{CNN-Specific Techniques}
\begin{itemize}
    \item \textbf{Feature Extraction}: Hierarchical representations from stacking convolutional layers.
    \item \textbf{Pooling Mechanisms}: Max-pooling for dimensionality reduction and translation invariance.
    \item \textbf{Activation Functions}: Non-linearities (e.g., ReLU) to enhance the network's learning capacity.
    \item \textbf{Dropout Regularization}: Prevents overfitting by randomly disabling neurons during training.
    \item \textbf{Optimization}: Adaptive optimizers like Adam to enhance convergence.
\end{itemize}

\section*{Comparison and Results}
\begin{itemize}
    \item CNNs outperformed other models in both accuracy and speed, achieving up to 96.03\% accuracy on a modified FER dataset.
    \item ResNet-50, while accurate, was computationally expensive and less suited for real-time tasks.
    \item RNNs excelled in handling temporal features but were less effective for static images.
    \item DTSCNN, though promising, requires further refinement for real-time use cases.
\end{itemize}

\subsection*{Scalable Real-Time Emotion Recognition using EfficientNetV2 and Resolution Scaling}

\subsubsection*{Base Model: EfficientNetV2}
EfficientNetV2 was chosen as the base model as it has a lower computational cost and performs well on a variety of different datasets.
In addition, the model has low inference times and therefore is a great option for a real time solution. [1]

\subsubsection*{Key Techniques}
\textbf{a. Resolution Scaling}
\begin{itemize}
    \item Adjust input resolution to improve accuracy.
    \item More flexibility makes it easier to use on different hardware.
\end{itemize}

\textbf{b. Data Augmentation}
\begin{itemize}
    \item Prior to training images were rotated, flipped, etc: to simulate real world conditions.
\end{itemize}

\textbf{c. Training Setup}
\begin{itemize}
    \item Used pre-trained image-net weights to accelerate training.
    \item Optimized with the Adam optimizer and a dynamic learning rate.
    \item Models trained for 120 epochs on the KDEF dataset.
\end{itemize}

\subsubsection*{Key Points}
\begin{itemize}
    \item \textbf{Real-time Execution:} Real time inference time was determined to be 40 ms.
    \item \textbf{Scalability:} Resolution scaling maintained performance across hardware with varying computational capabilities. It was successfully tested on an Intel-I5 processor.
\end{itemize}


\subsection*{Real-Time Emotional Analysis from A Live Webcam Using Deep Learning}

\subsubsection*{Base Models: MTCNN and VGG-16}
MTCNN was used for face detection while VGG-16 was used for facial emotion recognition classification. [2]

\subsubsection*{Key Techniques}
\textbf{a. Face Detection and Alignment}
\begin{itemize}
    \item Utilized MTCNN to accurately detect and align faces in live webcam feeds.
    \item Ensured consistent face positioning to improve classification accuracy.
\end{itemize}

\textbf{b. Feature Extraction and Classification}
\begin{itemize}
    \item Employed VGG-16 for extracting deep features from facial images.
    \item Applied Transfer Learning to fine-tune the pre-trained VGG-16 model on the FER2013 dataset.
\end{itemize}

\textbf{c. Real-Time Implementation}
\begin{itemize}
    \item Integrated OpenCV for capturing and processing live video streams.
    \item Achieved real-time emotion recognition by optimizing the processing pipeline.
\end{itemize}

\subsubsection*{Key Points}
\begin{itemize}
    \item \textbf{High Training Accuracy:} Achieved 97.23\% accuracy on the training set, demonstrating effective learning of facial emotion patterns.
    \item \textbf{Real-Time Performance:} Successfully implemented a system capable of processing live webcam feeds and displaying emotion classifications in real-time.
    \item \textbf{Hybrid Model Efficiency:} Combining MTCNN and VGG-16 provided a balanced trade-off between speed and accuracy, suitable for real-world applications.
    \item \textbf{Applicability:} Potential applications include patient monitoring, security surveillance, and e-learning environments.
\end{itemize}

\section*{Datasets}

\subsubsection*{FER2013 Dataset}
Based on our findings, we chose to work with the FER-2013 dataset due to its terms of service and availability.
The FER2013 dataset consists of grayscale images of faces, sized at 48x48 px. 
Faces are categorized into one of 7 discrete emotional states:

\begin{itemize}
    \item 0 = Angry
    \item 1 = Disgust
    \item 2 = Fear
    \item 3 = Happy
    \item 4 = Sad
    \item 5 = Surprise
    \item 6 = Neutral
\end{itemize}

The dataset is divided into two main subsets:
\begin{itemize}
    \item \textbf{Training Set:} 28,709 examples
    \item \textbf{Public Test Set:} 3,589 examples
\end{itemize}

\subsubsection*{Other Notable FER Datasets}
The FER-2013 dataset is readily available online and the dataset is relatively small making it an ideal option for small lightweight models.

\textbf{1. CK+ (Extended Cohn-Kanade):}
\begin{itemize}
    \item \textbf{Description:} Contains both posed and spontaneous facial expressions with detailed action units
    \item \textbf{Differences from FER2013:} Better option for dynamic emotional analysis in comparison to the static images available in FER 2013.
\end{itemize}

\textbf{2. JAFFE (Japanese Female Facial Expression):}
\begin{itemize}
    \item \textbf{Description:} Comprises 213 images of Japanese female subjects displaying seven emotions.
    \item \textbf{Differences from FER2013:} Dataset lack data variety and is suitable for specific problems.
\end{itemize}

\textbf{3. AffectNet:}
\begin{itemize}
    \item \textbf{Description:} Large dataset with 1 million samples that are labelled both on the discrete and valence emotion scales.
    \item \textbf{Differences from FER2013:} Data is annotated more richly with more detail
\end{itemize}

\textbf{4. RAF-DB (Real-world Affective Faces Database):}
\begin{itemize}
    \item \textbf{Description:} 30,000 images collected from the net that are labelled according to the 7 basic discrete emotions.
    \item \textbf{Differences from FER2013:} Dataset simulates real world conditions such as different lighting and backgrounds making it a harder but more accurate benchmark.
\end{itemize}

\subsubsection*{Considerations on Dataset Size and Image Resolution}

\textbf{Model Size and Dataset Size}

\begin{itemize}
    \item \textbf{Larger Datasets:} 
    \begin{itemize}
        \item Can support larger and more complex models with several layers and parameters.
        \item Larger dataset means a more varied training set and therefore a better generalized model.
        \item Requires more computation and training time.
    \end{itemize}
    \item \textbf{Smaller Datasets:}
    \begin{itemize}
        \item Works with smaller models.
        \item Can regain performance through techniques like transfer learning and data augmentation.
        \item Good for mobile solutions and when computational resources are limited.
    \end{itemize}
\end{itemize}

\textbf{Reasons for Choosing Smaller Datasets}

\begin{itemize}
    \item \textbf{Resource Constraints:} Used a Google Cloud instance with a T4 GPU (16Gb VRAM) for training and a M3 pro to test inference. 
    \item \textbf{Faster Experimentation:} Smaller datasets allow for quicker training and iteration during the development and tuning of models.
    \item \textbf{Availability and Terms of Service}: FER-2013 dataset is readily available for download on Kaggle hub and is relatively small.
\end{itemize}

\textbf{Impact of Image Resolution on Model Performance and Data Size}

\begin{itemize}
    \item \textbf{Higher Pixel Size (Resolution):}
    \begin{itemize}
        \item Provides more detailed information and can therefore capture more abstract patterns.
        \item Increases the amount of data per image, resulting in larger dataset sizes and higher computational and memory requirements.
        \item Increasing resolution means we need more parameters in the input layers to caputre the data in each pixel and therefore more reousrces.
    \end{itemize}
    \item \textbf{Lower Pixel Size (Resolution):}
    \begin{itemize}
        \item Reduces computational and memory requirements, enabling faster training and inference.
        \item May not capture more complex relationships due to lack of data.
        \item Helps in scenarios where bandwidth or storage is limited, making it easier to manage and process data.
    \end{itemize}
\end{itemize}

\section*{References}
\begin{enumerate}
    \item O. Ghadami, A. Rezvanian, and S. Shakuri, "Scalable Real-time Emotion Recognition using EfficientNetV2 and Resolution Scaling," 2024 10th International Conference on Web Research (ICWR), Tehran, Iran, 2024, pp. 1-7, doi: 10.1109/ICWR61162.2024.10533360.
    \item C. A. Kumar and K. Anitha Sheela, "Real-Time Emotional Analysis from A Live Webcam Using Deep Learning," 2022 3rd International Conference for Emerging Technology (INCET), Belgaum, India, 2022, pp. 1-5, doi: 10.1109/INCET54531.2022.9824894.
\end{enumerate}

\end{document}
